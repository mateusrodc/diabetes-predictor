{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed95687",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/scaler.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m X, y = split_features_labels(df)\n\u001b[32m     22\u001b[39m X_scaled, scaler = normalize_features(X)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msrc/scaler.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Etapa 2: Dividir em treino e teste\u001b[39;00m\n\u001b[32m     27\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(value, filename, compress, protocol)\u001b[39m\n\u001b[32m    597\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    600\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'src/scaler.pkl'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from data_preprocessing import load_and_clean_data, split_features_labels, normalize_features\n",
    "from model import get_models, train_model, evaluate_model, save_model\n",
    "\n",
    "# Etapa 1: Carregar e preparar dados\n",
    "df = load_and_clean_data('../data/diabetes.csv')\n",
    "X, y = split_features_labels(df)\n",
    "X_scaled, scaler = normalize_features(X)\n",
    "\n",
    "joblib.dump(scaler, '../src/scaler.pkl')\n",
    "\n",
    "# Etapa 2: Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Etapa 3: Treinar e avaliar modelos\n",
    "models = get_models()\n",
    "best_model = None\n",
    "best_score = 0\n",
    "best_name = ''\n",
    "\n",
    "for name, model in models.items():\n",
    "    trained = train_model(model, X_train, y_train)\n",
    "    acc, report, matrix = evaluate_model(trained, X_test, y_test)\n",
    "    print(f'\\n{name} - Acurácia: {acc:.4f}')\n",
    "\n",
    "    if acc > best_score:\n",
    "        best_model = trained\n",
    "        best_score = acc\n",
    "        best_name = name\n",
    "\n",
    "print(f'\\nMelhor modelo: {best_name} com acurácia de {best_score:.4f}')\n",
    "\n",
    "\n",
    "# Exemplo com Random Forest\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title('Matriz de Confusão - Random Forest')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "joblib.dump(best_model, '../src/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35e1eb-46e8-40ea-b164-1ac0747e41fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
